{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10160594,"sourceType":"datasetVersion","datasetId":6274021},{"sourceId":10208158,"sourceType":"datasetVersion","datasetId":6308869}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport sys\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport pyarrow.parquet as pq\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import roc_auc_score\nimport xgboost as xgb","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T13:56:34.153535Z","iopub.execute_input":"2024-12-18T13:56:34.154196Z","iopub.status.idle":"2024-12-18T13:56:36.067377Z","shell.execute_reply.started":"2024-12-18T13:56:34.154158Z","shell.execute_reply":"2024-12-18T13:56:36.066062Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Версия с эмбеддингами. Кэтбуст и xgboost, а также совместная модель","metadata":{}},{"cell_type":"markdown","source":"# Загрузка датасетов с фичами и подготовка эмбедденговых данных в трейне и тесте","metadata":{}},{"cell_type":"code","source":"# Загрузка и подготовка эмбеддинговых данных\nitems = pd.read_parquet('/kaggle/input/eda-simpmod-fi-vk-2024-a01-s06-datasets/items_meta.parquet.parquet')\nembeddings_df = pd.DataFrame(items['embeddings'].tolist(), index=items.index)\nitems = pd.concat([items, embeddings_df], axis=1)\ndel embeddings_df\nitems = items.drop(columns={'source_id',  'duration', 'embeddings'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:06:33.429076Z","iopub.execute_input":"2024-12-18T10:06:33.429510Z","iopub.status.idle":"2024-12-18T10:06:38.599494Z","shell.execute_reply.started":"2024-12-18T10:06:33.429481Z","shell.execute_reply":"2024-12-18T10:06:38.598535Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\"\"\"\nlinks = ['/kaggle/input/feature-data/train_interactions_0_25_data_all_featues.parquet',\n         '/kaggle/input/feature-data/train_interactions_25_50_data_all_featues.parquet',\n         '/kaggle/input/feature-data/train_interactions_50_75_data_all_featues.parquet',\n         '/kaggle/input/feature-data/train_interactions_75_100_data_all_featues.parquet',\n         '/kaggle/input/feature-data/train_interactions_100_125_data_all_featues.parquet',\n         '/kaggle/input/feature-data/train_interactions_125_143_data_all_featues.parquet']\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:06:38.600653Z","iopub.execute_input":"2024-12-18T10:06:38.600935Z","iopub.status.idle":"2024-12-18T10:06:38.607765Z","shell.execute_reply.started":"2024-12-18T10:06:38.600909Z","shell.execute_reply":"2024-12-18T10:06:38.606821Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"\"\\nlinks = ['/kaggle/input/feature-data/train_interactions_0_25_data_all_featues.parquet',\\n         '/kaggle/input/feature-data/train_interactions_25_50_data_all_featues.parquet',\\n         '/kaggle/input/feature-data/train_interactions_50_75_data_all_featues.parquet',\\n         '/kaggle/input/feature-data/train_interactions_75_100_data_all_featues.parquet',\\n         '/kaggle/input/feature-data/train_interactions_100_125_data_all_featues.parquet',\\n         '/kaggle/input/feature-data/train_interactions_125_143_data_all_featues.parquet']\\n\""},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"train100 = pd.read_parquet('/kaggle/input/feature-data/train_interactions_100_125_data_all_featues.parquet')\ntrain100 = train100.iloc[18_000_000:, :]\ntrain125 = pd.read_parquet('/kaggle/input/feature-data/train_interactions_125_143_data_all_featues.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:06:38.610161Z","iopub.execute_input":"2024-12-18T10:06:38.610901Z","iopub.status.idle":"2024-12-18T10:06:48.212861Z","shell.execute_reply.started":"2024-12-18T10:06:38.610872Z","shell.execute_reply":"2024-12-18T10:06:48.212159Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train = pd.concat([train100, train125], axis=0, ignore_index=True)\ndel train100, train125","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:06:48.213892Z","iopub.execute_input":"2024-12-18T10:06:48.214193Z","iopub.status.idle":"2024-12-18T10:06:48.661598Z","shell.execute_reply.started":"2024-12-18T10:06:48.214165Z","shell.execute_reply":"2024-12-18T10:06:48.660862Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Добавление эмбеддинговых данных в train\ntrain = train.merge(items, on='item_id', how='left')\ntrain = train.drop(columns={'item_id'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:06:48.662674Z","iopub.execute_input":"2024-12-18T10:06:48.663017Z","iopub.status.idle":"2024-12-18T10:07:00.039851Z","shell.execute_reply.started":"2024-12-18T10:06:48.662981Z","shell.execute_reply":"2024-12-18T10:07:00.039142Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Обучение модели CatBoost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostClassifier, Pool\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:07:00.040823Z","iopub.execute_input":"2024-12-18T10:07:00.041166Z","iopub.status.idle":"2024-12-18T10:07:00.045424Z","shell.execute_reply.started":"2024-12-18T10:07:00.041127Z","shell.execute_reply":"2024-12-18T10:07:00.044554Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# train0_25 = pd.read_parquet('/kaggle/working/train_interactions_0_25_data_all_featues.parquet')\n# train25_50 = pd.read_parquet('/kaggle/working/train_interactions_0_25_data_all_featues.parquet')\n# train0_25 = train25_50.drop(columns={'user_id', 'item_id'})\n# train25_50 = train25_50.drop(columns={'user_id', 'item_id'})\n# train = pd.concat([train0_25, train25_50], ignore_index=True)\n# del train0_25, train25_50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:07:00.046262Z","iopub.execute_input":"2024-12-18T10:07:00.046483Z","iopub.status.idle":"2024-12-18T10:07:00.056713Z","shell.execute_reply.started":"2024-12-18T10:07:00.046460Z","shell.execute_reply":"2024-12-18T10:07:00.056019Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Шаг 1: Разделяем данные\ny = train[\"like_dislike\"]\nX = train.drop(columns={\"like_dislike\"})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\ndel train, X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:07:00.057681Z","iopub.execute_input":"2024-12-18T10:07:00.057952Z","iopub.status.idle":"2024-12-18T10:07:23.066222Z","shell.execute_reply.started":"2024-12-18T10:07:00.057926Z","shell.execute_reply":"2024-12-18T10:07:23.065440Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Категориальные признаки\n# cat_features = ['gender_liked_mode', 'gender_difference']\ncat_features = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:07:23.069522Z","iopub.execute_input":"2024-12-18T10:07:23.069824Z","iopub.status.idle":"2024-12-18T10:07:23.073829Z","shell.execute_reply.started":"2024-12-18T10:07:23.069797Z","shell.execute_reply":"2024-12-18T10:07:23.072908Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Шаг 2: Создаём Pool для CatBoost\ntrain_pool = Pool(data=X_train, label=y_train, cat_features=cat_features)\ntest_pool = Pool(data=X_test, label=y_test, cat_features=cat_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:07:23.074772Z","iopub.execute_input":"2024-12-18T10:07:23.075013Z","iopub.status.idle":"2024-12-18T10:08:53.883992Z","shell.execute_reply.started":"2024-12-18T10:07:23.074988Z","shell.execute_reply":"2024-12-18T10:08:53.883321Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Шаг 3: Создаём и обучаем модель\nmodel = CatBoostClassifier(\n    thread_count=-1,\n    iterations=3000,\n    depth=7,\n    learning_rate=0.07,\n    l2_leaf_reg=15,\n    loss_function='MultiClass',   # Многоклассовая задача\n    eval_metric='AUC',            # Метрика для многоклассовой задачи\n    task_type='GPU',\n    devices='0-1',\n    verbose=100,\n    early_stopping_rounds=100,\n    bootstrap_type='Poisson',     # Указываем тип бутстрэпа\n    subsample=0.7,                # Применяем subsample с типом бутстрэпа Poisson\n    max_ctr_complexity=1,         # Длина перебора комбинаций фичей\n    border_count=254,             # Устанавливаем нужное количество границ\n    random_seed=42                # Фиксируем random seed\n)\n\n# Обучение модели на данных\nmodel.fit(\n    train_pool,\n    eval_set=test_pool,\n    use_best_model=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:08:53.884869Z","iopub.execute_input":"2024-12-18T10:08:53.885094Z","iopub.status.idle":"2024-12-18T10:37:41.111751Z","shell.execute_reply.started":"2024-12-18T10:08:53.885072Z","shell.execute_reply":"2024-12-18T10:37:41.110825Z"}},"outputs":[{"name":"stderr","text":"Default metric period is 5 because AUC is/are not implemented for GPU\nAUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n","output_type":"stream"},{"name":"stdout","text":"0:\ttest: 0.7566677\tbest: 0.7566677 (0)\ttotal: 1.03s\tremaining: 51m 40s\n100:\ttest: 0.9400639\tbest: 0.9400639 (100)\ttotal: 1m 6s\tremaining: 31m 39s\n200:\ttest: 0.9621929\tbest: 0.9622432 (194)\ttotal: 2m 10s\tremaining: 30m 12s\n300:\ttest: 0.9649983\tbest: 0.9649983 (300)\ttotal: 3m 13s\tremaining: 28m 52s\n400:\ttest: 0.9660671\tbest: 0.9660774 (395)\ttotal: 4m 15s\tremaining: 27m 38s\n500:\ttest: 0.9671639\tbest: 0.9671742 (491)\ttotal: 5m 18s\tremaining: 26m 26s\n600:\ttest: 0.9676710\tbest: 0.9676888 (551)\ttotal: 6m 20s\tremaining: 25m 18s\n700:\ttest: 0.9681852\tbest: 0.9681867 (699)\ttotal: 7m 22s\tremaining: 24m 10s\n800:\ttest: 0.9683598\tbest: 0.9683707 (777)\ttotal: 8m 23s\tremaining: 23m 2s\n900:\ttest: 0.9685777\tbest: 0.9685777 (900)\ttotal: 9m 24s\tremaining: 21m 55s\n1000:\ttest: 0.9685903\tbest: 0.9686024 (978)\ttotal: 10m 26s\tremaining: 20m 50s\n1100:\ttest: 0.9688372\tbest: 0.9688372 (1100)\ttotal: 11m 27s\tremaining: 19m 45s\n1200:\ttest: 0.9692804\tbest: 0.9692848 (1189)\ttotal: 12m 27s\tremaining: 18m 40s\n1300:\ttest: 0.9693782\tbest: 0.9693796 (1298)\ttotal: 13m 28s\tremaining: 17m 36s\n1400:\ttest: 0.9694782\tbest: 0.9694791 (1399)\ttotal: 14m 28s\tremaining: 16m 31s\n1500:\ttest: 0.9695075\tbest: 0.9695102 (1494)\ttotal: 15m 29s\tremaining: 15m 28s\n1600:\ttest: 0.9695961\tbest: 0.9695970 (1593)\ttotal: 16m 29s\tremaining: 14m 24s\n1700:\ttest: 0.9697160\tbest: 0.9697160 (1700)\ttotal: 17m 30s\tremaining: 13m 22s\n1800:\ttest: 0.9697800\tbest: 0.9697805 (1798)\ttotal: 18m 30s\tremaining: 12m 19s\n1900:\ttest: 0.9698020\tbest: 0.9698020 (1900)\ttotal: 19m 30s\tremaining: 11m 16s\n2000:\ttest: 0.9698603\tbest: 0.9698605 (1999)\ttotal: 20m 30s\tremaining: 10m 14s\n2100:\ttest: 0.9698760\tbest: 0.9698799 (2094)\ttotal: 21m 31s\tremaining: 9m 12s\n2200:\ttest: 0.9699165\tbest: 0.9699199 (2177)\ttotal: 22m 31s\tremaining: 8m 10s\n2300:\ttest: 0.9699677\tbest: 0.9699677 (2295)\ttotal: 23m 32s\tremaining: 7m 8s\n2400:\ttest: 0.9700407\tbest: 0.9700415 (2394)\ttotal: 24m 31s\tremaining: 6m 7s\n2500:\ttest: 0.9700585\tbest: 0.9700585 (2500)\ttotal: 25m 31s\tremaining: 5m 5s\n2600:\ttest: 0.9700650\tbest: 0.9700662 (2599)\ttotal: 26m 31s\tremaining: 4m 4s\n2700:\ttest: 0.9701077\tbest: 0.9701106 (2658)\ttotal: 27m 31s\tremaining: 3m 2s\nbestTest = 0.9701106004\nbestIteration = 2658\nShrink model to first 2659 iterations.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<catboost.core.CatBoostClassifier at 0x7f04c56c3310>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Шаг 4: Оцениваем модель\n# Получаем вероятности для каждого класса\ny_pred = model.predict_proba(test_pool)\n\n# Для многоклассовой классификации используем 'ovr' (one-vs-rest) или 'ovo' (one-vs-one)\nroc_auc = roc_auc_score(y_test, y_pred, multi_class='ovr', average='macro')\n\nprint(f\"ROC-AUC: {roc_auc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:37:41.112721Z","iopub.execute_input":"2024-12-18T10:37:41.113909Z","iopub.status.idle":"2024-12-18T10:37:57.722365Z","shell.execute_reply.started":"2024-12-18T10:37:41.113869Z","shell.execute_reply":"2024-12-18T10:37:57.721501Z"}},"outputs":[{"name":"stdout","text":"ROC-AUC: 0.9457\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Шаг 5: Создание Pool для тестовых данных\ntest = pd.read_parquet('/kaggle/input/feature-data/test_0_20_featues.parquet')\ntest = test.merge(items, on='item_id', how='left')\ntest = test.drop(columns={'item_id'})\ntest_pool = Pool(data=test, cat_features=cat_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:37:57.723713Z","iopub.execute_input":"2024-12-18T10:37:57.724169Z","iopub.status.idle":"2024-12-18T10:38:03.999484Z","shell.execute_reply.started":"2024-12-18T10:37:57.724127Z","shell.execute_reply":"2024-12-18T10:38:03.998760Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Шаг 6: Предсказание вероятностей\ntest['predicted_prob'] = model.predict_proba(test_pool)[:, 1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:38:04.000443Z","iopub.execute_input":"2024-12-18T10:38:04.000667Z","iopub.status.idle":"2024-12-18T10:38:12.679158Z","shell.execute_reply.started":"2024-12-18T10:38:04.000644Z","shell.execute_reply":"2024-12-18T10:38:12.678415Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"test.iloc[:,-1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:38:12.680226Z","iopub.execute_input":"2024-12-18T10:38:12.680512Z","iopub.status.idle":"2024-12-18T10:38:12.697237Z","shell.execute_reply.started":"2024-12-18T10:38:12.680483Z","shell.execute_reply":"2024-12-18T10:38:12.696442Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"         predicted_prob\n0              0.100804\n1              0.170159\n2              0.170517\n3              0.100435\n4              0.030966\n...                 ...\n1655115        0.000894\n1655116        0.009871\n1655117        0.001589\n1655118        0.001497\n1655119        0.005295\n\n[1655120 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predicted_prob</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.100804</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.170159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.170517</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.100435</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.030966</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1655115</th>\n      <td>0.000894</td>\n    </tr>\n    <tr>\n      <th>1655116</th>\n      <td>0.009871</td>\n    </tr>\n    <tr>\n      <th>1655117</th>\n      <td>0.001589</td>\n    </tr>\n    <tr>\n      <th>1655118</th>\n      <td>0.001497</td>\n    </tr>\n    <tr>\n      <th>1655119</th>\n      <td>0.005295</td>\n    </tr>\n  </tbody>\n</table>\n<p>1655120 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Шаг 7: Перезапись и сохранение результатов\nsubm = pd.read_csv('/kaggle/input/eda-simpmod-fi-vk-2024-a01-s06-datasets/sample_submission.csv')\nsubm['predict'] = test['predicted_prob']\nsubm.to_csv('/kaggle/working/submission_catboost_probabilities_18.12.csv', index=False)\nsubm.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T10:38:12.698237Z","iopub.execute_input":"2024-12-18T10:38:12.698491Z","iopub.status.idle":"2024-12-18T10:38:16.892095Z","shell.execute_reply.started":"2024-12-18T10:38:12.698467Z","shell.execute_reply":"2024-12-18T10:38:16.891264Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"   user_id  item_id   predict\n0        1     7363  0.100804\n1        1    73770  0.170159\n2        1    75700  0.170517\n3        1    81204  0.100435\n4        1   110249  0.030966","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7363</td>\n      <td>0.100804</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>73770</td>\n      <td>0.170159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>75700</td>\n      <td>0.170517</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>81204</td>\n      <td>0.100435</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>110249</td>\n      <td>0.030966</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"# Модель с эмбеддингами позволила получить метрику 0,6444736334 на приватном датасете","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T13:57:56.202356Z","iopub.execute_input":"2024-12-18T13:57:56.202984Z","iopub.status.idle":"2024-12-18T13:57:56.206506Z","shell.execute_reply.started":"2024-12-18T13:57:56.202951Z","shell.execute_reply":"2024-12-18T13:57:56.205643Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"\"\"\"\nfrom sklearn.inspection import permutation_importance\nimport matplotlib.pyplot as plt\n\nX_test = X_test.sample(200000, random_state=42)\ny_test = y_test.sample(200000, random_state=42)\nperm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\nsorted_idx = perm_importance.importances_mean.argsort()\nfig = plt.figure(figsize=(12, 9))\nplt.barh(range(len(sorted_idx)), perm_importance.importances_mean[sorted_idx], align='center')\nplt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\nplt.title('Permutation Importance');\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:20:18.548656Z","iopub.execute_input":"2024-12-16T13:20:18.548883Z","iopub.status.idle":"2024-12-16T13:20:18.560811Z","shell.execute_reply.started":"2024-12-16T13:20:18.548860Z","shell.execute_reply":"2024-12-16T13:20:18.559983Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"\\nfrom sklearn.inspection import permutation_importance\\nimport matplotlib.pyplot as plt\\n\\nX_test = X_test.sample(200000, random_state=42)\\ny_test = y_test.sample(200000, random_state=42)\\nperm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\\nsorted_idx = perm_importance.importances_mean.argsort()\\nfig = plt.figure(figsize=(12, 9))\\nplt.barh(range(len(sorted_idx)), perm_importance.importances_mean[sorted_idx], align='center')\\nplt.yticks(range(len(sorted_idx)), np.array(X_test.columns)[sorted_idx])\\nplt.title('Permutation Importance');\\n\""},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"del test, subm, y_pred, train_pool, test_pool, X_train, X_test, y_train, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-16T13:20:18.561722Z","iopub.execute_input":"2024-12-16T13:20:18.561950Z","iopub.status.idle":"2024-12-16T13:20:18.797053Z","shell.execute_reply.started":"2024-12-16T13:20:18.561926Z","shell.execute_reply":"2024-12-16T13:20:18.796223Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Автоматическое прохождение по чанкам и обучение XGBoost","metadata":{}},{"cell_type":"code","source":"# Функция для загрузки, обработки данных и добавления эмбеддингов\ndef process_datasets_with_embeddings(links, items):\n    \"\"\"\n    Обрабатывает список датасетов, добавляя к ним эмбеддинговые фичи.\n\n    Args:\n        links (list of str): Список ссылок на parquet-даты.\n        items (pd.DataFrame): Датасет с эмбеддингами.\n\n    Yields:\n        pd.DataFrame: Датасет с эмбеддингами.\n    \"\"\"\n    embeddings_df = pd.DataFrame(items['embeddings'].tolist(), index=items.index)\n    items = pd.concat([items, embeddings_df], axis=1)\n    items = items.drop(columns={'source_id', 'duration', 'embeddings'})\n    del embeddings_df\n\n    for link in links:\n        dataset = pd.read_parquet(link)\n        dataset = dataset.merge(items, on='item_id', how='left')\n        # dataset = dataset.drop(columns={'item_id'})\n        yield dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T13:58:07.743937Z","iopub.execute_input":"2024-12-18T13:58:07.744705Z","iopub.status.idle":"2024-12-18T13:58:07.750197Z","shell.execute_reply.started":"2024-12-18T13:58:07.744645Z","shell.execute_reply":"2024-12-18T13:58:07.749347Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train_and_evaluate_model(dataset, iteration, output_dir, train_chanks_result):\n    \"\"\"\n    Обучает XGBoost модель на данных, тестирует, сохраняет модель и записывает метрики.\n\n    Args:\n        dataset (pd.DataFrame): Обработанный датасет.\n        iteration (int): Индекс итерации для сохранения модели.\n        output_dir (str): Путь для сохранения моделей.\n        train_chanks_result (pd.DataFrame): Таблица результатов.\n\n    Returns:\n        pd.DataFrame: Обновлённая таблица результатов.\n    \"\"\"\n    # Преобразуем метки в диапазон [0, num_class-1]\n    dataset[\"like_dislike\"] = dataset[\"like_dislike\"] + 1  # Сдвигаем метки: -1 -> 0, 0 -> 1, 1 -> 2\n\n    # Проверяем наличие сохранённых моделей\n    model_files = [\n        f for f in os.listdir(output_dir) if f.startswith(\"model_iteration_\") and f.endswith(\".json\")\n    ]\n    if model_files:\n        # Находим последнюю модель\n        model_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n        latest_model_file = model_files[-1]\n        latest_model_path = os.path.join(output_dir, latest_model_file)\n        print(f\"Loading model from: {latest_model_path}\")\n        \n        # Загружаем существующую модель\n        base_model = xgb.Booster()\n        base_model.load_model(latest_model_path)\n        continue_training = True\n    else:\n        print(\"No existing model found. Creating a new model.\")\n        base_model = None\n        continue_training = False\n\n    # Разделяем данные\n    y = dataset[\"like_dislike\"]\n    X = dataset.drop(columns=[\"like_dislike\"])\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n    del dataset, X, y\n\n    # Создаём DMatrix для XGBoost\n    train_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n    test_dmatrix = xgb.DMatrix(data=X_test, label=y_test)\n\n    # Настраиваем параметры\n    params = {\n        \"objective\": \"multi:softprob\",\n        \"eval_metric\": \"mlogloss\",\n        \"eta\": 0.07,\n        \"max_depth\": 8,\n        \"subsample\": 0.7,\n        \"colsample_bytree\": 0.7,\n        \"lambda\": 25,  # Увеличиваем L2-регуляризацию\n        \"alpha\": 15,   # Добавляем L1-регуляризацию\n        \"num_class\": len(set(y_train)),  # Количество уникальных классов\n        \"random_state\": 42,\n        \"tree_method\": \"hist\",  # Используем метод hist для CPU, либо device для GPU\n        \"device\": \"cuda\"  # Если используете GPU, указать \"cuda\"\n    }\n\n    # Если продолжаем обучение, устанавливаем checkpoint\n    if continue_training:\n        print(\"Continuing training from the previous model.\")\n        base_iteration = int(latest_model_file.split('_')[-1].split('.')[0]) + 1\n    else:\n        base_iteration = 0\n    \n    # Обучаем модель\n    evals = [(train_dmatrix, \"train\"), (test_dmatrix, \"validation\")]\n    model = xgb.train(\n        params=params,\n        dtrain=train_dmatrix,\n        num_boost_round=250,  # Количество новых раундов обучения\n        evals=evals,\n        xgb_model=base_model,  # Указываем модель для продолжения обучения\n        verbose_eval=10  # Выводить информацию каждые 10 итераций\n    )\n    \n    # Оцениваем метрику ROC-AUC\n    y_pred = model.predict(test_dmatrix)\n    y_pred_classes = y_pred.argmax(axis=1)  # Преобразуем вероятности в классы\n    y_pred_original = y_pred_classes - 1  # Возвращаем метки в исходный диапазон (-1, 0, 1)\n    roc_auc = roc_auc_score(y_test - 1, y_pred, multi_class='ovr', average='macro')  # Обратный сдвиг для сравнения\n    print(f\"Iteration {iteration} - ROC-AUC: {roc_auc:.4f}\")\n    \n    # Сохраняем модель\n    model_path = os.path.join(output_dir, f\"model_iteration_{iteration}.json\")\n    model.save_model(model_path)\n    \n    # Записываем результаты\n    new_result = pd.DataFrame({\"iteration\": [iteration + base_iteration], \"roc_auc\": [roc_auc]})\n    train_chanks_result = pd.concat([train_chanks_result, new_result], ignore_index=True)\n    return train_chanks_result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T13:58:07.752073Z","iopub.execute_input":"2024-12-18T13:58:07.752507Z","iopub.status.idle":"2024-12-18T13:58:07.769745Z","shell.execute_reply.started":"2024-12-18T13:58:07.752469Z","shell.execute_reply":"2024-12-18T13:58:07.768933Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Запуск обучения\nif __name__ == \"__main__\":\n    items = pd.read_parquet('/kaggle/input/eda-simpmod-fi-vk-2024-a01-s06-datasets/items_meta.parquet.parquet')\n    links = [\n        '/kaggle/input/feature-data/train_interactions_0_25_data_all_featues.parquet',\n        '/kaggle/input/feature-data/train_interactions_25_50_data_all_featues.parquet',\n        '/kaggle/input/feature-data/train_interactions_50_75_data_all_featues.parquet',\n        '/kaggle/input/feature-data/train_interactions_75_100_data_all_featues.parquet',\n        '/kaggle/input/feature-data/train_interactions_100_125_data_all_featues.parquet',\n        '/kaggle/input/feature-data/train_interactions_125_143_data_all_featues.parquet'\n    ]\n\n    output_dir = \"/kaggle/working\"\n    train_chanks_result = pd.DataFrame(columns=[\"iteration\", \"bestTest\", \"roc_auc\"])\n\n    # Проходим по датасетам и обучаем модель\n    for i, dataset in enumerate(process_datasets_with_embeddings(links, items)):\n        train_chanks_result = train_and_evaluate_model(dataset, i, output_dir, train_chanks_result)\n\n    # Сохраняем результаты\n    train_chanks_result.to_csv(os.path.join(output_dir, \"train_chanks_result.csv\"), index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T13:58:07.770677Z","iopub.execute_input":"2024-12-18T13:58:07.770918Z","iopub.status.idle":"2024-12-18T15:30:24.394131Z","shell.execute_reply.started":"2024-12-18T13:58:07.770876Z","shell.execute_reply":"2024-12-18T15:30:24.391412Z"}},"outputs":[{"name":"stdout","text":"No existing model found. Creating a new model.\n[0]\ttrain-mlogloss:1.00809\tvalidation-mlogloss:1.00811\n[10]\ttrain-mlogloss:0.49910\tvalidation-mlogloss:0.49921\n[20]\ttrain-mlogloss:0.29816\tvalidation-mlogloss:0.29833\n[30]\ttrain-mlogloss:0.20942\tvalidation-mlogloss:0.20964\n[40]\ttrain-mlogloss:0.16727\tvalidation-mlogloss:0.16754\n[50]\ttrain-mlogloss:0.14677\tvalidation-mlogloss:0.14709\n[60]\ttrain-mlogloss:0.13572\tvalidation-mlogloss:0.13608\n[70]\ttrain-mlogloss:0.12942\tvalidation-mlogloss:0.12982\n[80]\ttrain-mlogloss:0.12606\tvalidation-mlogloss:0.12649\n[90]\ttrain-mlogloss:0.12391\tvalidation-mlogloss:0.12438\n[100]\ttrain-mlogloss:0.12257\tvalidation-mlogloss:0.12307\n[110]\ttrain-mlogloss:0.12169\tvalidation-mlogloss:0.12222\n[120]\ttrain-mlogloss:0.12103\tvalidation-mlogloss:0.12159\n[130]\ttrain-mlogloss:0.12058\tvalidation-mlogloss:0.12117\n[140]\ttrain-mlogloss:0.12025\tvalidation-mlogloss:0.12086\n[150]\ttrain-mlogloss:0.12000\tvalidation-mlogloss:0.12065\n[160]\ttrain-mlogloss:0.11980\tvalidation-mlogloss:0.12048\n[170]\ttrain-mlogloss:0.11963\tvalidation-mlogloss:0.12034\n[180]\ttrain-mlogloss:0.11948\tvalidation-mlogloss:0.12022\n[190]\ttrain-mlogloss:0.11936\tvalidation-mlogloss:0.12014\n[200]\ttrain-mlogloss:0.11924\tvalidation-mlogloss:0.12006\n[210]\ttrain-mlogloss:0.11915\tvalidation-mlogloss:0.11999\n[220]\ttrain-mlogloss:0.11905\tvalidation-mlogloss:0.11993\n[230]\ttrain-mlogloss:0.11895\tvalidation-mlogloss:0.11986\n[240]\ttrain-mlogloss:0.11888\tvalidation-mlogloss:0.11982\n[249]\ttrain-mlogloss:0.11881\tvalidation-mlogloss:0.11978\nIteration 0 - ROC-AUC: 0.2748\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_23/1599133232.py:94: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  train_chanks_result = pd.concat([train_chanks_result, new_result], ignore_index=True)\n","output_type":"stream"},{"name":"stdout","text":"Loading model from: /kaggle/working/model_iteration_0.json\nContinuing training from the previous model.\n[0]\ttrain-mlogloss:0.11972\tvalidation-mlogloss:0.11974\n[10]\ttrain-mlogloss:0.11950\tvalidation-mlogloss:0.11957\n[20]\ttrain-mlogloss:0.11938\tvalidation-mlogloss:0.11948\n[30]\ttrain-mlogloss:0.11927\tvalidation-mlogloss:0.11942\n[40]\ttrain-mlogloss:0.11918\tvalidation-mlogloss:0.11937\n[50]\ttrain-mlogloss:0.11911\tvalidation-mlogloss:0.11933\n[60]\ttrain-mlogloss:0.11904\tvalidation-mlogloss:0.11930\n[70]\ttrain-mlogloss:0.11898\tvalidation-mlogloss:0.11927\n[80]\ttrain-mlogloss:0.11892\tvalidation-mlogloss:0.11925\n[90]\ttrain-mlogloss:0.11886\tvalidation-mlogloss:0.11923\n[100]\ttrain-mlogloss:0.11880\tvalidation-mlogloss:0.11920\n[110]\ttrain-mlogloss:0.11874\tvalidation-mlogloss:0.11918\n[120]\ttrain-mlogloss:0.11869\tvalidation-mlogloss:0.11916\n[130]\ttrain-mlogloss:0.11863\tvalidation-mlogloss:0.11914\n[140]\ttrain-mlogloss:0.11857\tvalidation-mlogloss:0.11912\n[150]\ttrain-mlogloss:0.11852\tvalidation-mlogloss:0.11910\n[160]\ttrain-mlogloss:0.11847\tvalidation-mlogloss:0.11908\n[170]\ttrain-mlogloss:0.11841\tvalidation-mlogloss:0.11907\n[180]\ttrain-mlogloss:0.11836\tvalidation-mlogloss:0.11905\n[190]\ttrain-mlogloss:0.11830\tvalidation-mlogloss:0.11903\n[200]\ttrain-mlogloss:0.11824\tvalidation-mlogloss:0.11901\n[210]\ttrain-mlogloss:0.11819\tvalidation-mlogloss:0.11899\n[220]\ttrain-mlogloss:0.11813\tvalidation-mlogloss:0.11898\n[230]\ttrain-mlogloss:0.11807\tvalidation-mlogloss:0.11896\n[240]\ttrain-mlogloss:0.11802\tvalidation-mlogloss:0.11895\n[249]\ttrain-mlogloss:0.11798\tvalidation-mlogloss:0.11894\nIteration 1 - ROC-AUC: 0.2962\nLoading model from: /kaggle/working/model_iteration_1.json\nContinuing training from the previous model.\n[0]\ttrain-mlogloss:0.11792\tvalidation-mlogloss:0.11807\n[10]\ttrain-mlogloss:0.11775\tvalidation-mlogloss:0.11796\n[20]\ttrain-mlogloss:0.11764\tvalidation-mlogloss:0.11790\n[30]\ttrain-mlogloss:0.11755\tvalidation-mlogloss:0.11786\n[40]\ttrain-mlogloss:0.11747\tvalidation-mlogloss:0.11782\n[50]\ttrain-mlogloss:0.11740\tvalidation-mlogloss:0.11779\n[60]\ttrain-mlogloss:0.11734\tvalidation-mlogloss:0.11777\n[70]\ttrain-mlogloss:0.11728\tvalidation-mlogloss:0.11775\n[80]\ttrain-mlogloss:0.11722\tvalidation-mlogloss:0.11773\n[90]\ttrain-mlogloss:0.11716\tvalidation-mlogloss:0.11771\n[100]\ttrain-mlogloss:0.11711\tvalidation-mlogloss:0.11770\n[110]\ttrain-mlogloss:0.11705\tvalidation-mlogloss:0.11768\n[120]\ttrain-mlogloss:0.11699\tvalidation-mlogloss:0.11766\n[130]\ttrain-mlogloss:0.11695\tvalidation-mlogloss:0.11765\n[140]\ttrain-mlogloss:0.11689\tvalidation-mlogloss:0.11764\n[150]\ttrain-mlogloss:0.11684\tvalidation-mlogloss:0.11762\n[160]\ttrain-mlogloss:0.11679\tvalidation-mlogloss:0.11762\n[170]\ttrain-mlogloss:0.11674\tvalidation-mlogloss:0.11760\n[180]\ttrain-mlogloss:0.11669\tvalidation-mlogloss:0.11759\n[190]\ttrain-mlogloss:0.11665\tvalidation-mlogloss:0.11759\n[200]\ttrain-mlogloss:0.11660\tvalidation-mlogloss:0.11758\n[210]\ttrain-mlogloss:0.11655\tvalidation-mlogloss:0.11757\n[220]\ttrain-mlogloss:0.11650\tvalidation-mlogloss:0.11756\n[230]\ttrain-mlogloss:0.11646\tvalidation-mlogloss:0.11755\n[240]\ttrain-mlogloss:0.11641\tvalidation-mlogloss:0.11755\n[249]\ttrain-mlogloss:0.11637\tvalidation-mlogloss:0.11754\nIteration 2 - ROC-AUC: 0.3046\nLoading model from: /kaggle/working/model_iteration_2.json\nContinuing training from the previous model.\n[0]\ttrain-mlogloss:0.11983\tvalidation-mlogloss:0.11930\n[10]\ttrain-mlogloss:0.11968\tvalidation-mlogloss:0.11920\n[20]\ttrain-mlogloss:0.11958\tvalidation-mlogloss:0.11915\n[30]\ttrain-mlogloss:0.11949\tvalidation-mlogloss:0.11911\n[40]\ttrain-mlogloss:0.11941\tvalidation-mlogloss:0.11908\n[50]\ttrain-mlogloss:0.11934\tvalidation-mlogloss:0.11906\n[60]\ttrain-mlogloss:0.11928\tvalidation-mlogloss:0.11904\n[70]\ttrain-mlogloss:0.11921\tvalidation-mlogloss:0.11902\n[80]\ttrain-mlogloss:0.11915\tvalidation-mlogloss:0.11900\n[90]\ttrain-mlogloss:0.11909\tvalidation-mlogloss:0.11898\n[100]\ttrain-mlogloss:0.11904\tvalidation-mlogloss:0.11897\n[110]\ttrain-mlogloss:0.11898\tvalidation-mlogloss:0.11895\n[120]\ttrain-mlogloss:0.11893\tvalidation-mlogloss:0.11894\n[130]\ttrain-mlogloss:0.11887\tvalidation-mlogloss:0.11893\n[140]\ttrain-mlogloss:0.11882\tvalidation-mlogloss:0.11892\n[150]\ttrain-mlogloss:0.11877\tvalidation-mlogloss:0.11891\n[160]\ttrain-mlogloss:0.11872\tvalidation-mlogloss:0.11890\n[170]\ttrain-mlogloss:0.11867\tvalidation-mlogloss:0.11888\n[180]\ttrain-mlogloss:0.11862\tvalidation-mlogloss:0.11887\n[190]\ttrain-mlogloss:0.11857\tvalidation-mlogloss:0.11886\n[200]\ttrain-mlogloss:0.11852\tvalidation-mlogloss:0.11885\n[210]\ttrain-mlogloss:0.11847\tvalidation-mlogloss:0.11884\n[220]\ttrain-mlogloss:0.11842\tvalidation-mlogloss:0.11883\n[230]\ttrain-mlogloss:0.11838\tvalidation-mlogloss:0.11883\n[240]\ttrain-mlogloss:0.11833\tvalidation-mlogloss:0.11882\n[249]\ttrain-mlogloss:0.11829\tvalidation-mlogloss:0.11881\nIteration 3 - ROC-AUC: 0.3041\nLoading model from: /kaggle/working/model_iteration_3.json\nContinuing training from the previous model.\n[0]\ttrain-mlogloss:0.12198\tvalidation-mlogloss:0.12198\n[10]\ttrain-mlogloss:0.12177\tvalidation-mlogloss:0.12183\n[20]\ttrain-mlogloss:0.12163\tvalidation-mlogloss:0.12175\n[30]\ttrain-mlogloss:0.12153\tvalidation-mlogloss:0.12170\n[40]\ttrain-mlogloss:0.12143\tvalidation-mlogloss:0.12165\n[50]\ttrain-mlogloss:0.12135\tvalidation-mlogloss:0.12162\n[60]\ttrain-mlogloss:0.12128\tvalidation-mlogloss:0.12159\n[70]\ttrain-mlogloss:0.12121\tvalidation-mlogloss:0.12156\n[80]\ttrain-mlogloss:0.12115\tvalidation-mlogloss:0.12154\n[90]\ttrain-mlogloss:0.12109\tvalidation-mlogloss:0.12152\n[100]\ttrain-mlogloss:0.12103\tvalidation-mlogloss:0.12150\n[110]\ttrain-mlogloss:0.12098\tvalidation-mlogloss:0.12148\n[120]\ttrain-mlogloss:0.12092\tvalidation-mlogloss:0.12147\n[130]\ttrain-mlogloss:0.12087\tvalidation-mlogloss:0.12145\n[140]\ttrain-mlogloss:0.12082\tvalidation-mlogloss:0.12144\n[150]\ttrain-mlogloss:0.12077\tvalidation-mlogloss:0.12143\n[160]\ttrain-mlogloss:0.12072\tvalidation-mlogloss:0.12141\n[170]\ttrain-mlogloss:0.12067\tvalidation-mlogloss:0.12140\n[180]\ttrain-mlogloss:0.12062\tvalidation-mlogloss:0.12139\n[190]\ttrain-mlogloss:0.12057\tvalidation-mlogloss:0.12137\n[200]\ttrain-mlogloss:0.12052\tvalidation-mlogloss:0.12136\n[210]\ttrain-mlogloss:0.12047\tvalidation-mlogloss:0.12135\n[220]\ttrain-mlogloss:0.12043\tvalidation-mlogloss:0.12135\n[230]\ttrain-mlogloss:0.12038\tvalidation-mlogloss:0.12134\n[240]\ttrain-mlogloss:0.12034\tvalidation-mlogloss:0.12133\n[249]\ttrain-mlogloss:0.12029\tvalidation-mlogloss:0.12132\nIteration 4 - ROC-AUC: 0.3018\nLoading model from: /kaggle/working/model_iteration_4.json\nContinuing training from the previous model.\n[0]\ttrain-mlogloss:0.12379\tvalidation-mlogloss:0.12347\n[10]\ttrain-mlogloss:0.12361\tvalidation-mlogloss:0.12336\n[20]\ttrain-mlogloss:0.12349\tvalidation-mlogloss:0.12331\n[30]\ttrain-mlogloss:0.12339\tvalidation-mlogloss:0.12326\n[40]\ttrain-mlogloss:0.12329\tvalidation-mlogloss:0.12322\n[50]\ttrain-mlogloss:0.12321\tvalidation-mlogloss:0.12319\n[60]\ttrain-mlogloss:0.12314\tvalidation-mlogloss:0.12316\n[70]\ttrain-mlogloss:0.12306\tvalidation-mlogloss:0.12313\n[80]\ttrain-mlogloss:0.12299\tvalidation-mlogloss:0.12311\n[90]\ttrain-mlogloss:0.12293\tvalidation-mlogloss:0.12309\n[100]\ttrain-mlogloss:0.12287\tvalidation-mlogloss:0.12307\n[110]\ttrain-mlogloss:0.12280\tvalidation-mlogloss:0.12305\n[120]\ttrain-mlogloss:0.12273\tvalidation-mlogloss:0.12303\n[130]\ttrain-mlogloss:0.12267\tvalidation-mlogloss:0.12302\n[140]\ttrain-mlogloss:0.12261\tvalidation-mlogloss:0.12300\n[150]\ttrain-mlogloss:0.12255\tvalidation-mlogloss:0.12298\n[160]\ttrain-mlogloss:0.12249\tvalidation-mlogloss:0.12297\n[170]\ttrain-mlogloss:0.12243\tvalidation-mlogloss:0.12296\n[180]\ttrain-mlogloss:0.12238\tvalidation-mlogloss:0.12295\n[190]\ttrain-mlogloss:0.12233\tvalidation-mlogloss:0.12294\n[200]\ttrain-mlogloss:0.12227\tvalidation-mlogloss:0.12293\n[210]\ttrain-mlogloss:0.12222\tvalidation-mlogloss:0.12292\n[220]\ttrain-mlogloss:0.12216\tvalidation-mlogloss:0.12291\n[230]\ttrain-mlogloss:0.12211\tvalidation-mlogloss:0.12290\n[240]\ttrain-mlogloss:0.12206\tvalidation-mlogloss:0.12289\n[249]\ttrain-mlogloss:0.12201\tvalidation-mlogloss:0.12289\nIteration 5 - ROC-AUC: 0.3063\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Предсказание вероятностей\n# Шаг 1: Загрузка последней модели\noutput_dir = '/kaggle/working'  # Путь к папке с моделями\nmodel_files = [\n    f for f in os.listdir(output_dir) if f.startswith(\"model_iteration_\") and f.endswith(\".json\")\n]\n\nif model_files:\n    # Находим последнюю модель\n    model_files.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n    latest_model_file = model_files[-1]\n    latest_model_path = os.path.join(output_dir, latest_model_file)\n    print(f\"Loading model from: {latest_model_path}\")\n    \n    # Загружаем модель\n    model = xgb.Booster()\n    model.load_model(latest_model_path)\nelse:\n    raise ValueError(\"No model found to load\")\n\n# Шаг 2: Загрузка тестовых данных\nitems = pd.read_parquet('/kaggle/input/eda-simpmod-fi-vk-2024-a01-s06-datasets/items_meta.parquet.parquet')\nembeddings_df = pd.DataFrame(items['embeddings'].tolist(), index=items.index)\nitems = pd.concat([items, embeddings_df], axis=1)\ndel embeddings_df\nitems = items.drop(columns={'source_id',  'duration', 'embeddings'})\n\ntest = pd.read_parquet('/kaggle/input/feature-data/test_0_20_featues.parquet')\ntest = test.merge(items, on='item_id', how='left')\n# test = test.drop(columns={'item_id'})\n\n# Шаг 3: Обработка столбцов с типом 'object'\n# test = test.apply(pd.to_numeric, errors='ignore')  # Преобразование в числовые\n# test = test.select_dtypes(include=[int, float, bool, 'category'])\n\n# Шаг 4: Подготовка тестовых данных в формат DMatrix\ntest_dmatrix = xgb.DMatrix(test)\n\n# Шаг 5: Получение вероятностей для каждого класса\ny_pred = model.predict(test_dmatrix)  # Это будет массив с вероятностями для каждого класса\n\n# Шаг 6: Создание файла для submission\nsubm = pd.read_csv('/kaggle/input/eda-simpmod-fi-vk-2024-a01-s06-datasets/sample_submission.csv')\nsubm['predict'] = y_pred.tolist()  # Для многоклассовой классификации, y_pred будет массивом вероятностей для каждого объекта\n\n# Для многоклассовой классификации, y_pred будет 2D массивом:\n# Количество строк — это количество объектов, количество столбцов — количество классов.\n# Если нужно для каждого объекта предсказать вероятность определенного класса, \n# можно использовать `y_pred[:, class_index]`, например для класса 0:\n# subm['predict'] = y_pred[:, 0]  # Предсказание вероятности для класса 0\n\n# Шаг 7: Вычисление predict на основании полученного многомерного массива\nsubm_predict = pd.DataFrame(subm['predict'].tolist(), index=subm.index)\nsubm = pd.concat([subm, subm_predict], axis=1)\nsubm['predict'] = subm[2] - subm[0]\nsubm = subm[['user_id', 'item_id', 'predict']]\n\n# Clip data for 0 (makes trash results)\n# subm['predict'] = subm['predict'].apply(lambda x: max(x, 0))\n\n# Сохраняем результат\nsubm.to_csv('/kaggle/working/submission_xgb_probabilities.csv', index=False)\nsubm.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T15:30:24.405739Z","iopub.execute_input":"2024-12-18T15:30:24.406033Z","iopub.status.idle":"2024-12-18T15:32:18.676672Z","shell.execute_reply.started":"2024-12-18T15:30:24.406005Z","shell.execute_reply":"2024-12-18T15:32:18.675742Z"}},"outputs":[{"name":"stdout","text":"Loading model from: /kaggle/working/model_iteration_5.json\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"   user_id  item_id   predict\n0        1     7363  0.125653\n1        1    73770  0.142450\n2        1    75700  0.180228\n3        1    81204  0.126991\n4        1   110249  0.045290","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>7363</td>\n      <td>0.125653</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>73770</td>\n      <td>0.142450</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>75700</td>\n      <td>0.180228</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>81204</td>\n      <td>0.126991</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>110249</td>\n      <td>0.045290</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"subm.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T15:32:18.677579Z","iopub.execute_input":"2024-12-18T15:32:18.677819Z","iopub.status.idle":"2024-12-18T15:32:18.837465Z","shell.execute_reply.started":"2024-12-18T15:32:18.677796Z","shell.execute_reply":"2024-12-18T15:32:18.836604Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"            user_id       item_id       predict\ncount  1.655120e+06  1.655120e+06  1.655120e+06\nmean   9.434374e+04  1.703528e+05  1.087732e-01\nstd    5.249043e+04  9.780802e+04  1.447175e-01\nmin    1.000000e+00  1.000000e+00 -9.003843e-01\n25%    4.955375e+04  8.476400e+04  6.855862e-03\n50%    9.568500e+04  1.714620e+05  4.994055e-02\n75%    1.398602e+05  2.527330e+05  1.546676e-01\nmax    1.834030e+05  3.377250e+05  9.767173e-01","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>item_id</th>\n      <th>predict</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.655120e+06</td>\n      <td>1.655120e+06</td>\n      <td>1.655120e+06</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>9.434374e+04</td>\n      <td>1.703528e+05</td>\n      <td>1.087732e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.249043e+04</td>\n      <td>9.780802e+04</td>\n      <td>1.447175e-01</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>-9.003843e-01</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.955375e+04</td>\n      <td>8.476400e+04</td>\n      <td>6.855862e-03</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.568500e+04</td>\n      <td>1.714620e+05</td>\n      <td>4.994055e-02</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.398602e+05</td>\n      <td>2.527330e+05</td>\n      <td>1.546676e-01</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.834030e+05</td>\n      <td>3.377250e+05</td>\n      <td>9.767173e-01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":25}]}